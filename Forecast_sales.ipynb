{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor  # Import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train_data.csv')\n",
        "\n",
        "# Replace all occurrences of -1 with NaN in the entire DataFrame as they are considered invalid\n",
        "df.replace(-1, np.nan, inplace=True)\n",
        "\n",
        "\n",
        "# Function to replace outliers with the median\n",
        "def fill_outliers_with_median(df, numerical_columns):\n",
        "    for col in numerical_columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Replace outliers with median value of the column\n",
        "        median_value = df[col].median()\n",
        "        df[col] = df[col].apply(lambda x: median_value if x < lower_bound or x > upper_bound else x)\n",
        "    return df\n",
        "\n",
        "# Apply filling outliers with the median\n",
        "numerical_columns = ['che_pc_usd', 'che_perc_gdp', 'insurance_perc_che', 'population',\n",
        "                     'prev_perc', 'price_month', 'price_unit', 'public_perc_che', 'target']\n",
        "df_imputed = fill_outliers_with_median(df_imputed, numerical_columns)\n",
        "\n",
        "# Check the result after filling outliers with the median\n",
        "print(\"\\nData after filling outliers with median:\")\n",
        "print(df_imputed.head())\n",
        "\n",
        "# Preprocessing pipeline\n",
        "categorical_columns = ['brand', 'country', 'cluster_nl', 'indication', 'therapeutic_area']\n",
        "numerical_columns = ['che_pc_usd', 'che_perc_gdp', 'population', 'price_month', 'price_unit',\n",
        "                     'public_perc_che', 'prev_perc', 'price_month', 'price_unit', 'year', 'month',\n",
        "                      'day', 'day_of_week', 'days_since_launch']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),  # Impute missing numerical values with median\n",
        "            ('scaler', StandardScaler())  # Scale numerical data\n",
        "        ]), numerical_columns),\n",
        "\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing categorical values with the most frequent value\n",
        "            ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'))  # Handle unknown categories\n",
        "        ]), categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "df_imputed['date'] = pd.to_datetime(df_imputed['date'], errors='coerce')\n",
        "df_imputed['ind_launch_date'] = pd.to_datetime(df_imputed['ind_launch_date'], errors='coerce')\n",
        "\n",
        "# Impute missing 'ind_launch_date' with mode\n",
        "df_imputed['ind_launch_date'] = df_imputed['ind_launch_date'].fillna(df_imputed['ind_launch_date'].mode()[0])\n",
        "\n",
        "# Extract date-related features\n",
        "df_imputed['year'] = df_imputed['date'].dt.year\n",
        "df_imputed['month'] = df_imputed['date'].dt.month\n",
        "df_imputed['day'] = df_imputed['date'].dt.day\n",
        "df_imputed['day_of_week'] = df_imputed['date'].dt.dayofweek\n",
        "df_imputed['days_since_launch'] = (df_imputed['date'] - df_imputed['ind_launch_date']).dt.days\n",
        "\n",
        "# Define features and target\n",
        "X = df_imputed.drop(columns=['target', 'date', 'ind_launch_date'])  # Drop the target and date-related columns\n",
        "y = df_imputed['target']  # Target variable (monthly sales)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model (Decision Tree Regressor)\n",
        "model = DecisionTreeRegressor(random_state=66)  # Initialize DecisionTreeRegressor\n",
        "\n",
        "# Create a pipeline with preprocessing and model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Handle outliers in the submission data\n",
        "test_df = pd.read_csv('submission_data.csv')\n",
        "\n",
        "# Apply the same transformations as done with the training data\n",
        "test_df['date'] = pd.to_datetime(test_df['date'], errors='coerce')\n",
        "test_df['ind_launch_date'] = pd.to_datetime(test_df['ind_launch_date'], errors='coerce')\n",
        "test_df['year'] = test_df['date'].dt.year\n",
        "test_df['month'] = test_df['date'].dt.month\n",
        "test_df['day'] = test_df['date'].dt.day\n",
        "test_df['day_of_week'] = test_df['date'].dt.dayofweek\n",
        "test_df['days_since_launch'] = (test_df['date'] - test_df['ind_launch_date']).dt.days\n",
        "\n",
        "# Apply filling outliers with the median on the test data\n",
        "test_df = fill_outliers_with_median(test_df, numerical_columns)\n",
        "\n",
        "# Apply the same preprocessing pipeline to the test data\n",
        "test_predictions = pipeline.predict(test_df.drop(columns=['date', 'ind_launch_date']))\n",
        "\n",
        "# Load the submission template\n",
        "submission_template = pd.read_csv('submission_template.csv')\n",
        "\n",
        "# Ensure prediction order matches the template\n",
        "submission_template['prediction'] = test_predictions  # Fill in predictions\n",
        "\n",
        "# Save the final submission file\n",
        "submission_template.to_csv('final_submissionDT_.csv', index=False)\n",
        "print(\"Submission saved to 'final_submissionDT_.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUfgdZS6wZvi",
        "outputId": "0dc898c9-6e72-456d-9aae-2d4513064baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after filling outliers with median:\n",
            "        brand  che_pc_usd  che_perc_gdp               cluster_nl corporation  \\\n",
            "0  BRAND_354E    1.209114      1.665879  BRAND_354E_COUNTRY_88A3   CORP_D524   \n",
            "1  BRAND_626D         NaN           NaN  BRAND_626D_COUNTRY_8B47   CORP_01C7   \n",
            "2  BRAND_45D9    1.209114      1.665879  BRAND_45D9_COUNTRY_88A3   CORP_39F7   \n",
            "3  BRAND_D724    1.851280      2.051770  BRAND_D724_COUNTRY_445D   CORP_711A   \n",
            "4  BRAND_4887    1.791199      2.059130  BRAND_4887_COUNTRY_D8B0   CORP_443D   \n",
            "\n",
            "        country launch_date       date       drug_id ind_launch_date  ...  \\\n",
            "0  COUNTRY_88A3  2014-06-01 2014-06-01  DRUG_ID_8795      2019-11-01  ...   \n",
            "1  COUNTRY_8B47  2014-06-01 2014-06-01  DRUG_ID_E66E      2014-09-01  ...   \n",
            "2  COUNTRY_88A3  2014-06-01 2014-06-01  DRUG_ID_F272      2019-11-01  ...   \n",
            "3  COUNTRY_445D  2014-06-01 2014-06-01  DRUG_ID_1D4E      2019-11-01  ...   \n",
            "4  COUNTRY_D8B0  2014-06-01 2014-06-01  DRUG_ID_AA88      2019-11-01  ...   \n",
            "\n",
            "  price_month  price_unit  public_perc_che  therapeutic_area    target  year  \\\n",
            "0    1.006444    1.013784         1.835821    THER_AREA_980E  1.000784  2014   \n",
            "1         NaN    1.626677              NaN    THER_AREA_96D7  1.000000  2014   \n",
            "2         NaN    1.086580         1.835821    THER_AREA_96D7  1.002258  2014   \n",
            "3         NaN    1.213446         1.805970    THER_AREA_6CEE  1.068761  2014   \n",
            "4    1.018589    1.008708         1.880597    THER_AREA_6CEE  1.036312  2014   \n",
            "\n",
            "   month day  day_of_week  days_since_launch  \n",
            "0      6   1            6              -1979  \n",
            "1      6   1            6                -92  \n",
            "2      6   1            6              -1979  \n",
            "3      6   1            6              -1979  \n",
            "4      6   1            6              -1979  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Mean Absolute Error: 0.019741235656682597\n",
            "Submission saved to 'final_submissionDT_.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}